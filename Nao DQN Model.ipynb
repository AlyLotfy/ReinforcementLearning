{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 - Starting EPSILON: 1.0\n",
      "Step 1 - Yaw: 1.2000000000000004, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 1 - Decayed EPSILON: 0.995\n",
      "Episode 2 - Starting EPSILON: 0.995\n",
      "Step 1 - Yaw: -1.5, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 2 - Decayed EPSILON: 0.990025\n",
      "Episode 3 - Starting EPSILON: 0.990025\n",
      "Step 1 - Yaw: -0.5999999999999999, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 3 - Decayed EPSILON: 0.985074875\n",
      "Episode 4 - Starting EPSILON: 0.985074875\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 4 - Decayed EPSILON: 0.9801495006250001\n",
      "Episode 5 - Starting EPSILON: 0.9801495006250001\n",
      "Step 1 - Yaw: -1.5, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 5 - Decayed EPSILON: 0.9752487531218751\n",
      "Episode 6 - Starting EPSILON: 0.9752487531218751\n",
      "Step 1 - Yaw: -0.2999999999999998, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 6 - Decayed EPSILON: 0.9703725093562657\n",
      "Episode 7 - Starting EPSILON: 0.9703725093562657\n",
      "Step 1 - Yaw: 0.9000000000000001, Pitch: 0.39\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 7 - Decayed EPSILON: 0.9655206468094844\n",
      "Episode 8 - Starting EPSILON: 0.9655206468094844\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 8 - Decayed EPSILON: 0.960693043575437\n",
      "Episode 9 - Starting EPSILON: 0.960693043575437\n",
      "Step 1 - Yaw: 1.5000000000000007, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 9 - Decayed EPSILON: 0.9558895783575597\n",
      "Episode 10 - Starting EPSILON: 0.9558895783575597\n",
      "Step 1 - Yaw: -1.2, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 10 - Decayed EPSILON: 0.9511101304657719\n",
      "Episode 11 - Starting EPSILON: 0.9511101304657719\n",
      "Step 1 - Yaw: 1.2000000000000004, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 11 - Decayed EPSILON: 0.946354579813443\n",
      "Episode 12 - Starting EPSILON: 0.946354579813443\n",
      "Step 1 - Yaw: 1.2000000000000004, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 12 - Decayed EPSILON: 0.9416228069143757\n",
      "Episode 13 - Starting EPSILON: 0.9416228069143757\n",
      "Step 1 - Yaw: -0.2999999999999998, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 13 - Decayed EPSILON: 0.9369146928798039\n",
      "Episode 14 - Starting EPSILON: 0.9369146928798039\n",
      "Step 1 - Yaw: -1.5, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 14 - Decayed EPSILON: 0.9322301194154049\n",
      "Episode 15 - Starting EPSILON: 0.9322301194154049\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 15 - Decayed EPSILON: 0.9275689688183278\n",
      "Episode 16 - Starting EPSILON: 0.9275689688183278\n",
      "Step 1 - Yaw: 2.1000000000000005, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 16 - Decayed EPSILON: 0.9229311239742362\n",
      "Episode 17 - Starting EPSILON: 0.9229311239742362\n",
      "Step 1 - Yaw: -1.5, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 17 - Decayed EPSILON: 0.918316468354365\n",
      "Episode 18 - Starting EPSILON: 0.918316468354365\n",
      "Step 1 - Yaw: 1.2000000000000004, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 18 - Decayed EPSILON: 0.9137248860125932\n",
      "Episode 19 - Starting EPSILON: 0.9137248860125932\n",
      "Step 1 - Yaw: -1.5, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 19 - Decayed EPSILON: 0.9091562615825302\n",
      "Episode 20 - Starting EPSILON: 0.9091562615825302\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 20 - Decayed EPSILON: 0.9046104802746175\n",
      "Episode 21 - Starting EPSILON: 0.9046104802746175\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 21 - Decayed EPSILON: 0.9000874278732445\n",
      "Episode 22 - Starting EPSILON: 0.9000874278732445\n",
      "Step 1 - Yaw: 2.220446049250313e-16, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 22 - Decayed EPSILON: 0.8955869907338783\n",
      "Episode 23 - Starting EPSILON: 0.8955869907338783\n",
      "Step 1 - Yaw: -0.8999999999999999, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 23 - Decayed EPSILON: 0.8911090557802088\n",
      "Episode 24 - Starting EPSILON: 0.8911090557802088\n",
      "Step 1 - Yaw: 0.9000000000000001, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 24 - Decayed EPSILON: 0.8866535105013078\n",
      "Episode 25 - Starting EPSILON: 0.8866535105013078\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 25 - Decayed EPSILON: 0.8822202429488013\n",
      "Episode 26 - Starting EPSILON: 0.8822202429488013\n",
      "Step 1 - Yaw: 0.9000000000000001, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 26 - Decayed EPSILON: 0.8778091417340573\n",
      "Episode 27 - Starting EPSILON: 0.8778091417340573\n",
      "Step 1 - Yaw: 1.2000000000000004, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 27 - Decayed EPSILON: 0.8734200960253871\n",
      "Episode 28 - Starting EPSILON: 0.8734200960253871\n",
      "Step 1 - Yaw: 2.1000000000000005, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 28 - Decayed EPSILON: 0.8690529955452602\n",
      "Episode 29 - Starting EPSILON: 0.8690529955452602\n",
      "Step 1 - Yaw: 2.220446049250313e-16, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 29 - Decayed EPSILON: 0.8647077305675338\n",
      "Episode 30 - Starting EPSILON: 0.8647077305675338\n",
      "Step 1 - Yaw: 2.220446049250313e-16, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 30 - Decayed EPSILON: 0.8603841919146962\n",
      "Episode 31 - Starting EPSILON: 0.8603841919146962\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 31 - Decayed EPSILON: 0.8560822709551227\n",
      "Episode 32 - Starting EPSILON: 0.8560822709551227\n",
      "Step 1 - Yaw: 0.6000000000000003, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 32 - Decayed EPSILON: 0.851801859600347\n",
      "Episode 33 - Starting EPSILON: 0.851801859600347\n",
      "Step 1 - Yaw: -1.8, Pitch: 0.39\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 33 - Decayed EPSILON: 0.8475428503023453\n",
      "Episode 34 - Starting EPSILON: 0.8475428503023453\n",
      "Step 1 - Yaw: 0.9000000000000001, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 34 - Decayed EPSILON: 0.8433051360508336\n",
      "Episode 35 - Starting EPSILON: 0.8433051360508336\n",
      "Step 1 - Yaw: 2.220446049250313e-16, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 35 - Decayed EPSILON: 0.8390886103705794\n",
      "Episode 36 - Starting EPSILON: 0.8390886103705794\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 36 - Decayed EPSILON: 0.8348931673187264\n",
      "Episode 37 - Starting EPSILON: 0.8348931673187264\n",
      "Step 1 - Yaw: -1.5, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 37 - Decayed EPSILON: 0.8307187014821328\n",
      "Episode 38 - Starting EPSILON: 0.8307187014821328\n",
      "Step 1 - Yaw: -1.5, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 38 - Decayed EPSILON: 0.8265651079747222\n",
      "Episode 39 - Starting EPSILON: 0.8265651079747222\n",
      "Step 1 - Yaw: -1.8, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 39 - Decayed EPSILON: 0.8224322824348486\n",
      "Episode 40 - Starting EPSILON: 0.8224322824348486\n",
      "Step 1 - Yaw: -1.2, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 40 - Decayed EPSILON: 0.8183201210226743\n",
      "Episode 41 - Starting EPSILON: 0.8183201210226743\n",
      "Step 1 - Yaw: -1.8, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 41 - Decayed EPSILON: 0.8142285204175609\n",
      "Episode 42 - Starting EPSILON: 0.8142285204175609\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 42 - Decayed EPSILON: 0.810157377815473\n",
      "Episode 43 - Starting EPSILON: 0.810157377815473\n",
      "Step 1 - Yaw: 2.220446049250313e-16, Pitch: 0.39\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 43 - Decayed EPSILON: 0.8061065909263957\n",
      "Episode 44 - Starting EPSILON: 0.8061065909263957\n",
      "Step 1 - Yaw: 0.6000000000000003, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 44 - Decayed EPSILON: 0.8020760579717637\n",
      "Episode 45 - Starting EPSILON: 0.8020760579717637\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 45 - Decayed EPSILON: 0.798065677681905\n",
      "Episode 46 - Starting EPSILON: 0.798065677681905\n",
      "Step 1 - Yaw: -0.5999999999999999, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 46 - Decayed EPSILON: 0.7940753492934954\n",
      "Episode 47 - Starting EPSILON: 0.7940753492934954\n",
      "Step 1 - Yaw: -0.2999999999999998, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 47 - Decayed EPSILON: 0.7901049725470279\n",
      "Episode 48 - Starting EPSILON: 0.7901049725470279\n",
      "Step 1 - Yaw: -1.8, Pitch: 0.39\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 48 - Decayed EPSILON: 0.7861544476842928\n",
      "Episode 49 - Starting EPSILON: 0.7861544476842928\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 49 - Decayed EPSILON: 0.7822236754458713\n",
      "Episode 50 - Starting EPSILON: 0.7822236754458713\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 50 - Decayed EPSILON: 0.778312557068642\n",
      "Episode 51 - Starting EPSILON: 0.778312557068642\n",
      "Step 1 - Yaw: 2.1000000000000005, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 51 - Decayed EPSILON: 0.7744209942832988\n",
      "Episode 52 - Starting EPSILON: 0.7744209942832988\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 52 - Decayed EPSILON: 0.7705488893118823\n",
      "Episode 53 - Starting EPSILON: 0.7705488893118823\n",
      "Step 1 - Yaw: 2.220446049250313e-16, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 53 - Decayed EPSILON: 0.7666961448653229\n",
      "Episode 54 - Starting EPSILON: 0.7666961448653229\n",
      "Step 1 - Yaw: 0.6000000000000003, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 54 - Decayed EPSILON: 0.7628626641409962\n",
      "Episode 55 - Starting EPSILON: 0.7628626641409962\n",
      "Step 1 - Yaw: 1.5000000000000007, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 55 - Decayed EPSILON: 0.7590483508202912\n",
      "Episode 56 - Starting EPSILON: 0.7590483508202912\n",
      "Step 1 - Yaw: 0.9000000000000001, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 56 - Decayed EPSILON: 0.7552531090661897\n",
      "Episode 57 - Starting EPSILON: 0.7552531090661897\n",
      "Step 1 - Yaw: 1.2000000000000004, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 57 - Decayed EPSILON: 0.7514768435208588\n",
      "Episode 58 - Starting EPSILON: 0.7514768435208588\n",
      "Step 1 - Yaw: -1.2, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 58 - Decayed EPSILON: 0.7477194593032545\n",
      "Episode 59 - Starting EPSILON: 0.7477194593032545\n",
      "Step 1 - Yaw: -0.8999999999999999, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 59 - Decayed EPSILON: 0.7439808620067382\n",
      "Episode 60 - Starting EPSILON: 0.7439808620067382\n",
      "Step 1 - Yaw: -1.2, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 60 - Decayed EPSILON: 0.7402609576967045\n",
      "Episode 61 - Starting EPSILON: 0.7402609576967045\n",
      "Step 1 - Yaw: -0.8999999999999999, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 61 - Decayed EPSILON: 0.736559652908221\n",
      "Episode 62 - Starting EPSILON: 0.736559652908221\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 62 - Decayed EPSILON: 0.7328768546436799\n",
      "Episode 63 - Starting EPSILON: 0.7328768546436799\n",
      "Step 1 - Yaw: 1.5000000000000007, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "Episode 63 - Decayed EPSILON: 0.7292124703704616\n",
      "Episode 64 - Starting EPSILON: 0.7292124703704616\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 64 - Decayed EPSILON: 0.7255664080186093\n",
      "Episode 65 - Starting EPSILON: 0.7255664080186093\n",
      "Step 1 - Yaw: -0.5999999999999999, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Episode 65 - Decayed EPSILON: 0.7219385759785162\n",
      "Episode 66 - Starting EPSILON: 0.7219385759785162\n",
      "Step 1 - Yaw: -1.2, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 66 - Decayed EPSILON: 0.7183288830986236\n",
      "Episode 67 - Starting EPSILON: 0.7183288830986236\n",
      "Step 1 - Yaw: -1.2, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 67 - Decayed EPSILON: 0.7147372386831305\n",
      "Episode 68 - Starting EPSILON: 0.7147372386831305\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 68 - Decayed EPSILON: 0.7111635524897149\n",
      "Episode 69 - Starting EPSILON: 0.7111635524897149\n",
      "Step 1 - Yaw: -0.8999999999999999, Pitch: 0.39\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Episode 69 - Decayed EPSILON: 0.7076077347272662\n",
      "Episode 70 - Starting EPSILON: 0.7076077347272662\n",
      "Step 1 - Yaw: 2.220446049250313e-16, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Episode 70 - Decayed EPSILON: 0.7040696960536299\n",
      "Episode 71 - Starting EPSILON: 0.7040696960536299\n",
      "Step 1 - Yaw: 0.9000000000000001, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Episode 71 - Decayed EPSILON: 0.7005493475733617\n",
      "Episode 72 - Starting EPSILON: 0.7005493475733617\n",
      "Step 1 - Yaw: 0.9000000000000001, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Episode 72 - Decayed EPSILON: 0.697046600835495\n",
      "Episode 73 - Starting EPSILON: 0.697046600835495\n",
      "Step 1 - Yaw: 1.5000000000000007, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Episode 73 - Decayed EPSILON: 0.6935613678313175\n",
      "Episode 74 - Starting EPSILON: 0.6935613678313175\n",
      "Step 1 - Yaw: 1.5000000000000007, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Episode 74 - Decayed EPSILON: 0.6900935609921609\n",
      "Episode 75 - Starting EPSILON: 0.6900935609921609\n",
      "Step 1 - Yaw: 1.5000000000000007, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Episode 75 - Decayed EPSILON: 0.6866430931872001\n",
      "Episode 76 - Starting EPSILON: 0.6866430931872001\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 76 - Decayed EPSILON: 0.6832098777212641\n",
      "Episode 77 - Starting EPSILON: 0.6832098777212641\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: 0.39\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 77 - Decayed EPSILON: 0.6797938283326578\n",
      "Episode 78 - Starting EPSILON: 0.6797938283326578\n",
      "Step 1 - Yaw: 1.2000000000000004, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 78 - Decayed EPSILON: 0.6763948591909945\n",
      "Episode 79 - Starting EPSILON: 0.6763948591909945\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 79 - Decayed EPSILON: 0.6730128848950395\n",
      "Episode 80 - Starting EPSILON: 0.6730128848950395\n",
      "Step 1 - Yaw: -0.8999999999999999, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 80 - Decayed EPSILON: 0.6696478204705644\n",
      "Episode 81 - Starting EPSILON: 0.6696478204705644\n",
      "Step 1 - Yaw: 0.9000000000000001, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 81 - Decayed EPSILON: 0.6662995813682115\n",
      "Episode 82 - Starting EPSILON: 0.6662995813682115\n",
      "Step 1 - Yaw: 0.6000000000000003, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 82 - Decayed EPSILON: 0.6629680834613705\n",
      "Episode 83 - Starting EPSILON: 0.6629680834613705\n",
      "Step 1 - Yaw: 2.1000000000000005, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Episode 83 - Decayed EPSILON: 0.6596532430440636\n",
      "Episode 84 - Starting EPSILON: 0.6596532430440636\n",
      "Step 1 - Yaw: -0.8999999999999999, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 84 - Decayed EPSILON: 0.6563549768288433\n",
      "Episode 85 - Starting EPSILON: 0.6563549768288433\n",
      "Step 1 - Yaw: 1.5000000000000007, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 85 - Decayed EPSILON: 0.653073201944699\n",
      "Episode 86 - Starting EPSILON: 0.653073201944699\n",
      "Step 1 - Yaw: 0.6000000000000003, Pitch: -0.41\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 86 - Decayed EPSILON: 0.6498078359349755\n",
      "Episode 87 - Starting EPSILON: 0.6498078359349755\n",
      "Step 1 - Yaw: 0.3000000000000005, Pitch: -0.61\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 87 - Decayed EPSILON: 0.6465587967553006\n",
      "Episode 88 - Starting EPSILON: 0.6465587967553006\n",
      "Step 1 - Yaw: -0.8999999999999999, Pitch: -0.20999999999999996\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 88 - Decayed EPSILON: 0.6433260027715241\n",
      "Episode 89 - Starting EPSILON: 0.6433260027715241\n",
      "Step 1 - Yaw: -0.2999999999999998, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 89 - Decayed EPSILON: 0.6401093727576664\n",
      "Episode 90 - Starting EPSILON: 0.6401093727576664\n",
      "Step 1 - Yaw: 0.6000000000000003, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Episode 90 - Decayed EPSILON: 0.6369088258938781\n",
      "Episode 91 - Starting EPSILON: 0.6369088258938781\n",
      "Step 1 - Yaw: -0.5999999999999999, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Episode 91 - Decayed EPSILON: 0.6337242817644086\n",
      "Episode 92 - Starting EPSILON: 0.6337242817644086\n",
      "Step 1 - Yaw: 2.1000000000000005, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 92 - Decayed EPSILON: 0.6305556603555866\n",
      "Episode 93 - Starting EPSILON: 0.6305556603555866\n",
      "Step 1 - Yaw: 0.6000000000000003, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 93 - Decayed EPSILON: 0.6274028820538087\n",
      "Episode 94 - Starting EPSILON: 0.6274028820538087\n",
      "Step 1 - Yaw: 2.220446049250313e-16, Pitch: 0.39\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Episode 94 - Decayed EPSILON: 0.6242658676435396\n",
      "Episode 95 - Starting EPSILON: 0.6242658676435396\n",
      "Step 1 - Yaw: 1.8000000000000005, Pitch: 0.5900000000000002\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 95 - Decayed EPSILON: 0.6211445383053219\n",
      "Episode 96 - Starting EPSILON: 0.6211445383053219\n",
      "Step 1 - Yaw: -1.8, Pitch: -0.009999999999999898\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 96 - Decayed EPSILON: 0.6180388156137953\n",
      "Episode 97 - Starting EPSILON: 0.6180388156137953\n",
      "Step 1 - Yaw: -0.8999999999999999, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Episode 97 - Decayed EPSILON: 0.6149486215357263\n",
      "Episode 98 - Starting EPSILON: 0.6149486215357263\n",
      "Step 1 - Yaw: 2.1000000000000005, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Episode 98 - Decayed EPSILON: 0.6118738784280476\n",
      "Episode 99 - Starting EPSILON: 0.6118738784280476\n",
      "Step 1 - Yaw: -1.5, Pitch: 0.19000000000000006\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Episode 99 - Decayed EPSILON: 0.6088145090359074\n",
      "Episode 100 - Starting EPSILON: 0.6088145090359074\n",
      "Step 1 - Yaw: -0.2999999999999998, Pitch: 0.7900000000000001\n",
      "Step 1 - Reward: -1.0\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 - Decayed EPSILON: 0.6057704364907278\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import socket\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import random\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Constants for head movement\n",
    "YAW_MIN, YAW_MAX = -1.8, 1.8\n",
    "PITCH_MIN, PITCH_MAX = -0.610, 0.610\n",
    "YAW_STEP_SIZE = 0.3\n",
    "PITCH_STEP_SIZE = 0.2\n",
    "\n",
    "# Action Space\n",
    "ACTIONS = [\n",
    "    (yaw, pitch)\n",
    "    for yaw in np.arange(YAW_MIN, YAW_MAX + YAW_STEP_SIZE, YAW_STEP_SIZE)\n",
    "    for pitch in np.arange(PITCH_MIN, PITCH_MAX + PITCH_STEP_SIZE, PITCH_STEP_SIZE)\n",
    "]\n",
    "\n",
    "# DQN Hyperparameters\n",
    "STATE_SIZE = (84, 84, 1)  # Grayscale for efficiency\n",
    "ACTION_SPACE_SIZE = len(ACTIONS)\n",
    "GAMMA = 0.95\n",
    "EPSILON = 1.0\n",
    "EPSILON_DECAY = 0.995\n",
    "MIN_EPSILON = 0.01\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "TARGET_UPDATE = 5\n",
    "\n",
    "# Replay Memory\n",
    "memory = deque(maxlen=2000)\n",
    "\n",
    "# Model Building\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=STATE_SIZE),\n",
    "        layers.Conv2D(64, (4, 4), strides=(2, 2), activation='relu'),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(ACTION_SPACE_SIZE, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mse')\n",
    "    return model\n",
    "\n",
    "dqn_model = build_model()\n",
    "target_model = build_model()\n",
    "target_model.set_weights(dqn_model.get_weights())\n",
    "\n",
    "# Action Selection\n",
    "def choose_action(state):\n",
    "    global EPSILON\n",
    "    if np.random.rand() <= EPSILON:\n",
    "        return random.choice(ACTIONS)\n",
    "    q_values = dqn_model.predict(np.expand_dims(state, axis=0), verbose=0)\n",
    "    return ACTIONS[np.argmax(q_values[0])]\n",
    "\n",
    "# Store Transition\n",
    "def store_transition(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "# Training the DQN\n",
    "def train_dqn():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    minibatch = random.sample(memory, BATCH_SIZE)\n",
    "    states = np.array([transition[0] for transition in minibatch])\n",
    "    actions = [ACTIONS.index(transition[1]) for transition in minibatch]\n",
    "    rewards = np.array([transition[2] for transition in minibatch])\n",
    "    next_states = np.array([transition[3] for transition in minibatch])\n",
    "    dones = np.array([transition[4] for transition in minibatch])\n",
    "\n",
    "    target_qs = dqn_model.predict(states)\n",
    "    next_qs = target_model.predict(next_states)\n",
    "    for idx, (action_idx, reward, done) in enumerate(zip(actions, rewards, dones)):\n",
    "        if done:\n",
    "            target_qs[idx][action_idx] = reward\n",
    "        else:\n",
    "            target_qs[idx][action_idx] = reward + GAMMA * np.max(next_qs[idx])\n",
    "    dqn_model.fit(states, target_qs, epochs=1, verbose=0)\n",
    "\n",
    "# Reward Calculation\n",
    "def calculate_reward(ball_position, frame_center):\n",
    "    if ball_position is None:\n",
    "        return -1.0\n",
    "    distance = np.linalg.norm(np.array(ball_position) - np.array(frame_center))\n",
    "    return 1.0 - (distance / np.linalg.norm(frame_center))\n",
    "\n",
    "# Detect Color Object\n",
    "def detect_color_object(frame, target_color=(0, 0, 255), kernel_size=7, min_area=500, debug=True):\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    lower_red1 = np.array([0, 120, 70])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 120, 70])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask1 = cv.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = mask1 | mask2\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel)\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    ball_position = None\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv.contourArea(contour)\n",
    "        if area > min_area:\n",
    "            (x, y), radius = cv.minEnclosingCircle(contour)\n",
    "            center = (int(x), int(y))\n",
    "            if radius > 0:\n",
    "                ball_position = center\n",
    "                if debug:\n",
    "                    cv.circle(frame, center, int(radius), target_color, 2)\n",
    "                    cv.circle(frame, center, 5, (0, 255, 0), -1)\n",
    "                break\n",
    "    return ball_position\n",
    "\n",
    "# Socket Initialization\n",
    "client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "client_socket.connect(('1.1.1.244', 65432))\n",
    "\n",
    "try:\n",
    "    for episode in range(100):\n",
    "        print(\"Episode {} - Starting EPSILON: {}\".format(episode + 1, EPSILON))\n",
    "        image_path = r\"C:\\\\Users\\\\ADMIN\\\\Downloads\\\\Nao\\\\image_1.jpg\"\n",
    "        image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(\"Error: Could not load image at {}\".format(image_path))\n",
    "            exit(1)\n",
    "        image = cv.resize(image, (84, 84))\n",
    "        state = np.array(image) / 255.0\n",
    "        state = np.expand_dims(state, axis=-1)\n",
    "        done = False\n",
    "        MAX_STEPS = 100\n",
    "        threshold_distance = 10\n",
    "        step_count = 0\n",
    "\n",
    "        while not done:\n",
    "            step_count += 1\n",
    "            action = choose_action(state)\n",
    "            head_yaw, head_pitch = action\n",
    "            print(\"Step {} - Yaw: {}, Pitch: {}\".format(step_count, head_yaw, head_pitch))\n",
    "            data = struct.pack(\"!ff\", head_yaw, head_pitch)\n",
    "            client_socket.sendall(data)\n",
    "            flag = client_socket.recv(8)\n",
    "            \n",
    "            # Convert grayscale to BGR for color detection\n",
    "            image = cv.cvtColor(image, cv.COLOR_GRAY2BGR)\n",
    "            ball_position = detect_color_object(image)\n",
    "            \n",
    "            # Process next state\n",
    "            next_image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "            next_image = cv.resize(next_image, (84, 84))\n",
    "            next_state = np.array(next_image) / 255.0\n",
    "            next_state = np.expand_dims(next_state, axis=-1)\n",
    "\n",
    "            height, width = next_image.shape[:2]\n",
    "            frame_center = (width // 2, height // 2)\n",
    "            reward = calculate_reward(ball_position, frame_center)\n",
    "            print(\"Step {} - Reward: {}\".format(step_count, reward))\n",
    "\n",
    "            store_transition(state, action, reward, next_state, done)\n",
    "            train_dqn()\n",
    "            state = next_state\n",
    "\n",
    "            if ball_position is None or step_count >= MAX_STEPS:\n",
    "                done = True\n",
    "            else:\n",
    "                distance = np.linalg.norm(np.array(ball_position) - np.array(frame_center))\n",
    "                if distance < threshold_distance:\n",
    "                    done = True\n",
    "\n",
    "        if EPSILON > MIN_EPSILON:\n",
    "            EPSILON *= EPSILON_DECAY\n",
    "            print(\"Episode {} - Decayed EPSILON: {}\".format(episode + 1, EPSILON))\n",
    "\n",
    "        if episode % TARGET_UPDATE == 0:\n",
    "            target_model.set_weights(dqn_model.get_weights())\n",
    "    dqn_model.save(\"dqn_trained_model.h5\")\n",
    "\n",
    "finally:\n",
    "    client_socket.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
